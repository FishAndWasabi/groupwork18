static bool dl_param_changed(struct task_struct *p,
static int __sched_setscheduler(struct task_struct *p,
				const struct sched_attr *attr,
				bool user)
				bool user, bool pi)
{
	int newprio = dl_policy(attr->sched_policy) ? MAX_DL_PRIO - 1 :
		      MAX_RT_PRIO - 1 - attr->sched_priority;

static int __sched_setscheduler(struct task_struct *p,	p->sched_reset_on_fork = reset_on_fork;
	oldprio = p->prio;

	/*
	 * Take priority boosted tasks into account. If the new
	 * effective priority is unchanged, we just store the new
	 * normal parameters and do not touch the scheduler class and
	 * the runqueue. This will be done when the task deboost
	 * itself.
	 */
	new_effective_prio = rt_mutex_get_effective_prio(p, newprio);
	if (new_effective_prio == oldprio) {
		__setscheduler_params(p, attr);
		task_rq_unlock(rq, p, &flags);
		return 0;
	if (pi) {
		/*
		 * Take priority boosted tasks into account. If the new
		 * effective priority is unchanged, we just store the new
		 * normal parameters and do not touch the scheduler class and
		 * the runqueue. This will be done when the task deboost
		 * itself.
		 */
		new_effective_prio = rt_mutex_get_effective_prio(p, newprio);
		if (new_effective_prio == oldprio) {
			__setscheduler_params(p, attr);
			task_rq_unlock(rq, p, &flags);
			return 0;
		}
	}

	queued = task_on_rq_queued(p);

static int __sched_setscheduler(struct task_struct *p,		put_prev_task(rq, p);

	prev_class = p->sched_class;
	__setscheduler(rq, p, attr, true);
	__setscheduler(rq, p, attr, pi);

	if (running)
		p->sched_class->set_curr_task(rq);

static int __sched_setscheduler(struct task_struct *p,	check_class_changed(rq, p, prev_class, oldprio);
	task_rq_unlock(rq, p, &flags);

	rt_mutex_adjust_pi(p);
	if (pi)
		rt_mutex_adjust_pi(p);

	return 0;
}

static int _sched_setscheduler(struct task_struct *p, int policy,		attr.sched_policy = policy;
	}

	return __sched_setscheduler(p, &attr, check);
	return __sched_setscheduler(p, &attr, check, true);
}
/**
 * sched_setscheduler - change the scheduling policy and/or RT priority of a thread.

EXPORT_SYMBOL_GPL(sched_setscheduler);
int sched_setattr(struct task_struct *p, const struct sched_attr *attr)
{
	return __sched_setscheduler(p, attr, true);
	return __sched_setscheduler(p, attr, true, true);
}
EXPORT_SYMBOL_GPL(sched_setattr);


EXPORT_SYMBOL(___might_sleep);#endif

#ifdef CONFIG_MAGIC_SYSRQ
static void normalize_task(struct rq *rq, struct task_struct *p)
void normalize_rt_tasks(void)
{
	const struct sched_class *prev_class = p->sched_class;
	struct task_struct *g, *p;
	struct sched_attr attr = {
		.sched_policy = SCHED_NORMAL,
	};
	int old_prio = p->prio;
	int queued;

	queued = task_on_rq_queued(p);
	if (queued)
		dequeue_task(rq, p, 0);
	__setscheduler(rq, p, &attr, false);
	if (queued) {
		enqueue_task(rq, p, 0);
		resched_curr(rq);
	}

	check_class_changed(rq, p, prev_class, old_prio);
}

void normalize_rt_tasks(void)
{
	struct task_struct *g, *p;
	unsigned long flags;
	struct rq *rq;

	read_lock(&tasklist_lock);
	for_each_process_thread(g, p) {

void normalize_rt_tasks(void)			continue;
		}

		rq = task_rq_lock(p, &flags);
		normalize_task(rq, p);
		task_rq_unlock(rq, p, &flags);
		__sched_setscheduler(p, &attr, false, false);
	}
	read_unlock(&tasklist_lock);
}


