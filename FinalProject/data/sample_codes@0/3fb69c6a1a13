static inline pte_t *hugepte_offset(hugepd_t hpd, unsigned long addr,	unsigned long idx = 0;

	pte_t *dir = hugepd_page(hpd);
#ifndef CONFIG_PPC_FSL_BOOK3E
#ifdef CONFIG_PPC_8xx
	idx = (addr & ((1UL << pdshift) - 1)) >> PAGE_SHIFT;
#elif !defined(CONFIG_PPC_FSL_BOOK3E)
	idx = (addr & ((1UL << pdshift) - 1)) >> hugepd_shift(hpd);
#endif


static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,	if (pshift >= pdshift) {
		cachep = PGT_CACHE(PTE_T_ORDER);
		num_hugepd = 1 << (pshift - pdshift);
	} else if (IS_ENABLED(CONFIG_PPC_8xx)) {
		cachep = PGT_CACHE(PTE_INDEX_SIZE);
		num_hugepd = 1;
	} else {
		cachep = PGT_CACHE(pdshift - pshift);
		num_hugepd = 1;

static void free_hugepd_range(struct mmu_gather *tlb, hugepd_t *hpdp, int pdshif
	if (shift >= pdshift)
		hugepd_free(tlb, hugepte);
	else if (IS_ENABLED(CONFIG_PPC_8xx))
		pgtable_free_tlb(tlb, hugepte,
				 get_hugepd_cache_index(PTE_INDEX_SIZE));
	else
		pgtable_free_tlb(tlb, hugepte,
				 get_hugepd_cache_index(pdshift - shift));

static int __init hugetlbpage_init(void)		 * if we have pdshift and shift value same, we don't
		 * use pgt cache for hugepd.
		 */
		if (pdshift > shift)
		if (pdshift > shift && IS_ENABLED(CONFIG_PPC_8xx))
			pgtable_cache_add(PTE_INDEX_SIZE);
		else if (pdshift > shift)
			pgtable_cache_add(pdshift - shift);
#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)
		else

struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {		.shift	= 14,
	},
#endif
	[MMU_PAGE_512K] = {
		.shift	= 19,
	},
	[MMU_PAGE_8M] = {
		.shift	= 23,
	},


